import sys 
import json
import pickle
import pandas as pd
from nltk.stem import  SnowballStemmer
from sklearn.feature_extraction.text import CountVectorizer
from collections import Counter

import sklearn

# para pre-procesamiento del texto y extraer características
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from nltk.stem import  SnowballStemmer


# algoritmos de clasificación
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

# para construir pipelines
from sklearn.pipeline import Pipeline

# para evaluar los modelos 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
from sklearn.utils.multiclass import unique_labels
#import tweepy

# x = {
#    "sum": int(sys.argv[1]) + int(sys.argv[2]) 
# }
#tweets = sys.argv[1]

print(sklearn.__version__)

tweets = ['Feo', 'Inutil', 'Se cree que la luna está aún más lejos']

#listado de stopwords. Este listado también se puede leer desde un fichero utilizando la función read_corpus
stop_words=[
'a',
'actualmente',
'adelante',
'además',
'afirmó',
'agregó',
'ahora',
'ahí',
'al',
'algo',
'alguna',
'algunas',
'alguno',
'algunos',
'algún',
'alrededor',
'ambos',
'ampleamos',
'ante',
'anterior',
'antes',
'apenas',
'aproximadamente',
'aquel',
'aquellas',
'aquellos',
'aqui',
'aquí',
'arriba',
'aseguró',
'así',
'atras',
'aunque',
'ayer',
'añadió',
'aún',
'bajo',
'bastante',
'bien',
'buen',
'buena',
'buenas',
'bueno',
'buenos',
'cada',
'casi',
'cerca',
'cierta',
'ciertas',
'cierto',
'ciertos',
'cinco',
'comentó',
'como',
'con',
'conocer',
'conseguimos',
'conseguir',
'considera',
'consideró',
'consigo',
'consigue',
'consiguen',
'consigues',
'contra',
'cosas',
'creo',
'cual',
'cuales',
'cualquier',
'cuando',
'cuanto',
'cuatro',
'cuenta',
'cómo',
'da',
'dado',
'dan',
'dar',
'de',
'debe',
'deben',
'debido',
'decir',
'dejó',
'del',
'demás',
'dentro',
'desde',
'después',
'dice',
'dicen',
'dicho',
'dieron',
'diferente',
'diferentes',
'dijeron',
'dijo',
'dio',
'donde',
'dos',
'durante',
'e',
'ejemplo',
'el',
'ella',
'ellas',
'ello',
'ellos',
'embargo',
'empleais',
'emplean',
'emplear',
'empleas',
'empleo',
'en',
'encima',
'encuentra',
'entonces',
'entre',
'era',
'erais',
'eramos',
'eran',
'eras',
'eres',
'es',
'esa',
'esas',
'ese',
'eso',
'esos',
'esta',
'estaba',
'estabais',
'estaban',
'estabas',
'estad',
'estada',
'estadas',
'estado',
'estados',
'estais',
'estamos',
'estan',
'estando',
'estar',
'estaremos',
'estará',
'estarán',
'estarás',
'estaré',
'estaréis',
'estaría',
'estaríais',
'estaríamos',
'estarían',
'estarías',
'estas',
'este',
'estemos',
'esto',
'estos',
'estoy',
'estuve',
'estuviera',
'estuvierais',
'estuvieran',
'estuvieras',
'estuvieron',
'estuviese',
'estuvieseis',
'estuviesen',
'estuvieses',
'estuvimos',
'estuviste',
'estuvisteis',
'estuviéramos',
'estuviésemos',
'estuvo',
'está',
'estábamos',
'estáis',
'están',
'estás',
'esté',
'estéis',
'estén',
'estés',
'ex',
'existe',
'existen',
'explicó',
'expresó',
'fin',
'fue',
'fuera',
'fuerais',
'fueran',
'fueras',
'fueron',
'fuese',
'fueseis',
'fuesen',
'fueses',
'fui',
'fuimos',
'fuiste',
'fuisteis',
'fuéramos',
'fuésemos',
'gran',
'grandes',
'gueno',
'ha',
'haber',
'habida',
'habidas',
'habido',
'habidos',
'habiendo',
'habremos',
'habrá',
'habrán',
'habrás',
'habré',
'habréis',
'habría',
'habríais',
'habríamos',
'habrían',
'habrías',
'habéis',
'había',
'habíais',
'habíamos',
'habían',
'habías',
'hace',
'haceis',
'hacemos',
'hacen',
'hacer',
'hacerlo',
'haces',
'hacia',
'haciendo',
'hago',
'han',
'has',
'hasta',
'hay',
'haya',
'hayamos',
'hayan',
'hayas',
'hayáis',
'he',
'hecho',
'hemos',
'hicieron',
'hizo',
'hoy',
'hube',
'hubiera',
'hubierais',
'hubieran',
'hubieras',
'hubieron',
'hubiese',
'hubieseis',
'hubiesen',
'hubieses',
'hubimos',
'hubiste',
'hubisteis',
'hubiéramos',
'hubiésemos',
'hubo',
'igual',
'incluso',
'indicó',
'informó',
'intenta',
'intentais',
'intentamos',
'intentan',
'intentar',
'intentas',
'intento',
'ir',
'junto',
'la',
'lado',
'largo',
'las',
'le',
'les',
'llegó',
'lleva',
'llevar',
'lo',
'los',
'luego',
'lugar',
'manera',
'manifestó',
'mayor',
'me',
'mediante',
'mejor',
'mencionó',
'menos',
'mi',
'mientras',
'mio',
'mis',
'misma',
'mismas',
'mismo',
'mismos',
'modo',
'momento',
'mucha',
'muchas',
'mucho',
'muchos',
'muy',
'más',
'mí',
'mía',
'mías',
'mío',
'míos',
'nada',
'nadie',
'ni',
'ninguna',
'ningunas',
'ninguno',
'ningunos',
'ningún',
'no',
'nos',
'nosotras',
'nosotros',
'nuestra',
'nuestras',
'nuestro',
'nuestros',
'nueva',
'nuevas',
'nuevo',
'nuevos',
'nunca',
'o',
'ocho',
'os',
'otra',
'otras',
'otro',
'otros',
'para',
'parece',
'parte',
'partir',
'pasada',
'pasado',
'pero',
'pesar',
'poca',
'pocas',
'poco',
'pocos',
'podeis',
'podemos',
'poder',
'podria',
'podriais',
'podriamos',
'podrian',
'podrias',
'podrá',
'podrán',
'podría',
'podrían',
'poner',
'por',
'por qué',
'porque',
'posible',
'primer',
'primera',
'primero',
'primeros',
'principalmente',
'propia',
'propias',
'propio',
'propios',
'próximo',
'próximos',
'pudo',
'pueda',
'puede',
'pueden',
'puedo',
'pues',
'que',
'quedó',
'queremos',
'quien',
'quienes',
'quiere',
'quién',
'qué',
'realizado',
'realizar',
'realizó',
'respecto',
'sabe',
'sabeis',
'sabemos',
'saben',
'saber',
'sabes',
'se',
'sea',
'seamos',
'sean',
'seas',
'segunda',
'segundo',
'según',
'seis',
'ser',
'seremos',
'será',
'serán',
'serás',
'seré',
'seréis',
'sería',
'seríais',
'seríamos',
'serían',
'serías',
'seáis',
'señaló',
'si',
'sido',
'siempre',
'siendo',
'siete',
'sigue',
'siguiente',
'sin',
'sino',
'sobre',
'sois',
'sola',
'solamente',
'solas',
'solo',
'solos',
'somos',
'son',
'soy',
'su',
'sus',
'suya',
'suyas',
'suyo',
'suyos',
'sí',
'sólo',
'tal',
'también',
'tampoco',
'tan',
'tanto',
'te',
'tendremos',
'tendrá',
'tendrán',
'tendrás',
'tendré',
'tendréis',
'tendría',
'tendríais',
'tendríamos',
'tendrían',
'tendrías',
'tened',
'teneis',
'tenemos',
'tener',
'tenga',
'tengamos',
'tengan',
'tengas',
'tengo',
'tengáis',
'tenida',
'tenidas',
'tenido',
'tenidos',
'teniendo',
'tenéis',
'tenía',
'teníais',
'teníamos',
'tenían',
'tenías',
'tercera',
'ti',
'tiempo',
'tiene',
'tienen',
'tienes',
'toda',
'todas',
'todavía',
'todo',
'todos',
'total',
'trabaja',
'trabajais',
'trabajamos',
'trabajan',
'trabajar',
'trabajas',
'trabajo',
'tras',
'trata',
'través',
'tres',
'tu',
'tus',
'tuve',
'tuviera',
'tuvierais',
'tuvieran',
'tuvieras',
'tuvieron',
'tuviese',
'tuvieseis',
'tuviesen',
'tuvieses',
'tuvimos',
'tuviste',
'tuvisteis',
'tuviéramos',
'tuviésemos',
'tuvo',
'tuya',
'tuyas',
'tuyo',
'tuyos',
'tú',
'ultimo',
'un',
'una',
'unas',
'uno',
'unos',
'usa',
'usais',
'usamos',
'usan',
'usar',
'usas',
'uso',
'usted',
'va',
'vais',
'valor',
'vamos',
'van',
'varias',
'varios',
'vaya',
'veces',
'ver',
'verdad',
'verdadera',
'verdadero',
'vez',
'vosotras',
'vosotros',
'voy',
'vuestra',
'vuestras',
'vuestro',
'vuestros',
'y',
'ya',
'yo',
'él',
'éramos',
'ésta',
'éstas',
'éste',
'éstos',
'última',
'últimas',
'último',
'últimos'
]

# carga un pipeline entrenado y guardado previamente
def load_model(rutaModelo = "pickle_model.pkl"):
  # Load from file
  with open(rutaModelo, 'rb') as file:
    pickle_model = pickle.load(file)
    return pickle_model 

# función auxiliar para realizar predicciones con el modelo
def predict_model(model, data, pref='m'):
  """
  data: list of the text to predict
  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)
  """
  res = {}
  scores = None
  labels = model.predict(data)

  if hasattr(model, 'predict_proba'):
    scores = model.predict_proba(data)
  
    # empaquetar scores dentro de un diccionario que contiene labels, scores clase 1, scores clase 2, .... El nombre de la clase se normaliza a lowercase
    res = {f'scores_{pref}_{cls.lower()}':score for cls, score in zip(model.classes_, [col for col in scores.T])}

  # añadir datos relativos a la predicción
  res[f'labels_{pref}'] = labels

  # convertir a dataframe ordenando las columnas primero el label y luego los scores por clase, las clases ordenadas alfabeticamente.
  res = pd.DataFrame(res, columns=sorted(list(res.keys())))

  return res

# función auxiliar utilizada por CountVectorizer para procesar las frases
def english_stemmer(sentence):
    #ponemos un stemmer en español
    stemmer = SnowballStemmer('spanish')
    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=stop_words,
                               ngram_range=(1, 1)).build_analyzer()
    return (stemmer.stem(word) for word in analyzer(sentence))

#print("Hacemos la llamada a twitter pasandole los params", terminos, fecha)


#-------------------------------------------------------------------------------------------------------------------

# cargar pipeline entrenado
model = load_model()

print('Modelo cargado')

# predecir los nuevos datos.
m_pred = predict_model(model, tweets, pref='m')

print(m_pred)

# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función
pred_labels = m_pred['labels_m'].values[0]
pred_proba = m_pred['scores_m_no'].values[0]

#--------------------------------------------------------------------------------------------------------------------



resPuestaAnalyzer = [
    {
        "usuario" : "@bernardoMontes",
        "tweet" : "No entiendo como pueden haber hecho esto los de @Cocacola @ferguson",
        "prediccion" : "0.2",
        "imagenUsuario" : "https://pbs.twimg.com/profile_images/1067571541825581057/mLuZfnDh_normal.jpg",
        "localizacion" : "Melbourne, Australia"

    },
    {
        "usuario" : "@saraSoni",
        "tweet" : "Me parece muy bien como los han tratado @UNICEF",
        "prediccion" : "0.95",
        "imagenUsuario" : "https://pbs.twimg.com/profile_images/1255180470767108096/y15mxXqs_normal.jpg",
        "localizacion" : "Copenhagen"

    },
    {
        "usuario" : "@saraSoni",
        "tweet" : "Sin duda se merecen nuestra enhorabuena @ferguson",
        "prediccion" : "0.89",
        "imagenUsuario" : "https://pbs.twimg.com/profile_images/514089485722611712/yGoJPl7J_normal.jpeg",
        "localizacion" : "Copenhagen"

    },
    {
        "usuario" : "@RobertoLeal",
        "tweet" : "Me gusta mucho el plan de marketing de @Cocacola",
        "prediccion" : "0.78",
        "imagenUsuario" : "https://pbs.twimg.com/profile_images/378800000343665972/dbc215bbb7dca6241497324e88e3d7c2_normal.png",
        "localizacion" : "London, UK"

    },
]

print(resPuestaAnalyzer)